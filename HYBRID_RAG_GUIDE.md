# ðŸ”€ Hybrid RAG System Guide

## Overview

Your app now supports **two RAG modes** that can be toggled via environment variable:

1. **Self-Hosted RAG** (Default) - PubMedBERT + Railway backend
2. **Gemini File Search** (New) - Google Gemini API + Cerebras LLM

---

## ðŸŽ¯ **Quick Start**

### **Switch to Gemini Mode:**

```bash
# In your .env file
RAG_MODE="gemini"
GOOGLE_AI_API_KEY="your-google-ai-api-key"
```

### **Stay on Self-Hosted Mode:**

```bash
# In your .env file
RAG_MODE="self-hosted"
RAG_BACKEND_URL="https://your-railway-backend.railway.app"
```

---

## ðŸ“Š **Mode Comparison**

| Feature | Self-Hosted | Gemini |
|---------|-------------|--------|
| **Embedding Model** | PubMedBERT (medical-specific) | Gemini (general-purpose) |
| **Infrastructure** | Railway backend (8GB RAM) | Google Cloud (serverless) |
| **Startup Time** | 10-20 sec (model loading) | Instant |
| **Memory Usage** | ~2GB (with models loaded) | ~0MB (API only) |
| **Cost per Query** | $0 (self-hosted) | ~$0.01-0.02 |
| **Monthly Cost** | ~$30 (Railway) | ~$20-40 (API usage) |
| **Medical Accuracy** | â­â­â­â­â­ (domain-specific) | â­â­â­â­ (good) |
| **Data Privacy** | âœ… Your infrastructure | âš ï¸ Sent to Google |
| **Maintenance** | ðŸ”§ High (dependencies, models) | âœ… Low (API only) |
| **Scalability** | Limited by Railway plan | â™¾ï¸ Unlimited |

---

## ðŸ—ï¸ **Architecture**

### **Self-Hosted Mode:**

```
User uploads PDF
    â†“
Next.js API â†’ Railway Backend
    â†“
Extract text (PyMuPDF)
    â†“
Chunk text (LangChain)
    â†“
Generate embeddings (PubMedBERT - 768 dim)
    â†“
Store in Supabase (pgvector)
    â†“
User queries
    â†“
Retrieve similar chunks (cosine similarity)
    â†“
Generate answer (Cerebras Llama 3.3 70B)
    â†“
Return answer + citations
```

### **Gemini Mode:**

```
User uploads PDF
    â†“
Next.js API â†’ Gemini File API
    â†“
Upload to Google Cloud Storage
    â†“
Gemini indexes document automatically
    â†“
User queries
    â†“
Gemini File Search (retrieves context)
    â†“
Generate answer (Cerebras Llama 3.3 70B)
    â†“
Return answer + citations
```

---

## ðŸ’° **Cost Breakdown**

### **Self-Hosted (Current):**

```
Railway Backend (8GB RAM):  $30/month
Supabase (free tier):       $0/month
Cerebras LLM:               $0.60/1M tokens
--------------------------------
Total: ~$30-40/month (fixed)
```

### **Gemini Mode:**

```
File upload:     $0.0025 per 1K tokens
Storage:         $0.001 per 1K tokens per day
Search:          $0.01 per 1K tokens
Cerebras LLM:    $0.60/1M tokens
--------------------------------
Total: ~$20-40/month (usage-based)

Example (100 PDFs, 1000 queries/month):
- Upload: 100 PDFs Ã— 10K tokens Ã— $0.0025 = $2.50
- Storage: 100 PDFs Ã— 10K tokens Ã— $0.001 Ã— 30 days = $30
- Search: 1000 queries Ã— 2K tokens Ã— $0.01 = $20
- LLM: 1000 queries Ã— 1K tokens Ã— $0.0006 = $0.60
Total: ~$53/month
```

**Note:** Gemini costs scale with usage, self-hosted is fixed.

---

## ðŸš€ **Setup Instructions**

### **Option 1: Gemini Mode (Recommended for Testing)**

1. **Get Google AI API Key:**
   ```bash
   # Go to: https://aistudio.google.com/apikey
   # Create new API key
   ```

2. **Update .env:**
   ```bash
   RAG_MODE="gemini"
   GOOGLE_AI_API_KEY="your-api-key-here"
   CEREBRAS_API_KEY="your-cerebras-key"
   ```

3. **Deploy:**
   ```bash
   git add .
   git commit -m "Switch to Gemini RAG mode"
   git push
   ```

4. **Test:**
   - Upload a PDF
   - Ask questions
   - Check Railway logs for `[GEMINI]` messages

### **Option 2: Self-Hosted Mode (Current)**

1. **Keep existing .env:**
   ```bash
   RAG_MODE="self-hosted"
   RAG_BACKEND_URL="https://your-backend.railway.app"
   SUPABASE_URL="https://your-project.supabase.co"
   SUPABASE_KEY="your-key"
   ```

2. **Ensure Railway backend is running**

3. **No code changes needed!**

---

## ðŸ”§ **API Usage**

### **Upload Document:**

```typescript
import { getUnifiedRAGService } from "@/lib/rag/unified-rag-service";

const ragService = getUnifiedRAGService();

// Works with both modes!
const result = await ragService.uploadDocument(
  fileBuffer,
  "medical-paper.pdf",
  userId,
  "application/pdf"
);

console.log(`Mode: ${result.mode}`); // "gemini" or "self-hosted"
console.log(`Document ID: ${result.documentId}`);
```

### **Chat with Document:**

```typescript
const response = await ragService.chat(
  documentId,
  "What are the side effects?",
  userId
);

console.log(`Answer: ${response.answer}`);
console.log(`Mode: ${response.mode}`);
console.log(`Provider: ${response.provider}`); // "cerebras" or "gemini"
```

---

## ðŸ“ **Implementation Details**

### **Files Created:**

1. **`src/lib/rag/gemini-file-search.ts`**
   - Gemini File API wrapper
   - Upload, search, delete files
   - Handles file metadata

2. **`src/lib/rag/unified-rag-service.ts`**
   - Unified interface for both modes
   - Automatic mode detection from env
   - Routes to appropriate service

3. **`env-template.txt`**
   - Added `RAG_MODE` variable
   - Added `RAG_BACKEND_URL` variable
   - Documentation for both modes

### **Key Features:**

âœ… **Zero code changes** to switch modes  
âœ… **Automatic fallback** if one mode fails  
âœ… **Consistent API** across both modes  
âœ… **Cost tracking** per mode  
âœ… **Performance monitoring**  

---

## ðŸ§ª **Testing Checklist**

### **Gemini Mode:**

- [ ] Upload PDF (check Railway logs for `[GEMINI]`)
- [ ] Verify file uploaded to Google
- [ ] Ask question
- [ ] Verify answer uses Cerebras (cost-optimized)
- [ ] Check answer quality vs self-hosted
- [ ] Test with medical terminology
- [ ] Monitor API costs in Google Cloud Console

### **Self-Hosted Mode:**

- [ ] Upload PDF (check Railway logs for `[SELF-HOSTED]`)
- [ ] Verify chunks in Supabase
- [ ] Ask question
- [ ] Verify embeddings search works
- [ ] Check memory usage on Railway
- [ ] Test with large PDFs (>100 pages)

---

## ðŸŽ¯ **Recommendations**

### **Use Gemini Mode If:**

âœ… You want to **reduce infrastructure costs**  
âœ… You're okay with **data going to Google**  
âœ… You want **instant startup** (no model loading)  
âœ… You need **unlimited scalability**  
âœ… You prefer **low maintenance**  

### **Use Self-Hosted Mode If:**

âœ… **Medical accuracy** is critical (PubMedBERT)  
âœ… You need **full data privacy**  
âœ… You want **no vendor lock-in**  
âœ… Your usage will **scale to where self-hosted is cheaper**  
âœ… You want **complete control** over embeddings  

---

## ðŸ”„ **Migration Path**

### **From Self-Hosted â†’ Gemini:**

1. Set `RAG_MODE="gemini"` in .env
2. Add `GOOGLE_AI_API_KEY`
3. Deploy
4. Test with sample PDFs
5. Compare answer quality
6. If satisfied, shut down Railway backend
7. Save ~$30/month on infrastructure

### **From Gemini â†’ Self-Hosted:**

1. Set `RAG_MODE="self-hosted"` in .env
2. Ensure Railway backend is running
3. Deploy
4. Re-upload all PDFs (Gemini files won't transfer)
5. Test embeddings search
6. Monitor memory usage

---

## ðŸ“Š **Monitoring**

### **Check Current Mode:**

```typescript
const ragService = getUnifiedRAGService();
console.log(`Current mode: ${ragService.getMode()}`);
```

### **Railway Logs:**

```bash
# Gemini mode
ðŸŽ¯ RAG Mode: GEMINI
ðŸ“¤ [GEMINI] Uploading medical-paper.pdf...
âœ… File uploaded: files/abc123
ðŸ’¬ [GEMINI] Searching and answering...
âœ… [GEMINI + CEREBRAS] Answer generated

# Self-hosted mode
ðŸŽ¯ RAG Mode: SELF-HOSTED
ðŸ“¤ [SELF-HOSTED] Uploading medical-paper.pdf...
âœ… Document processed: 45 chunks, 120 entities
ðŸ’¬ [SELF-HOSTED] Querying document...
âœ… Answer generated
```

---

## ðŸš¨ **Troubleshooting**

### **"Gemini service not initialized"**

```bash
# Missing API key
GOOGLE_AI_API_KEY="your-key-here"
```

### **"Backend returned 502"**

```bash
# Railway backend crashed or wrong URL
RAG_BACKEND_URL="https://correct-url.railway.app"
```

### **"File upload failed"**

```bash
# Check file size (Gemini: 2GB max)
# Check API quota in Google Cloud Console
```

---

## ðŸŽ‰ **Summary**

You now have a **flexible, toggleable RAG system**:

- **One environment variable** switches modes
- **Zero code changes** required
- **Cost-optimized** hybrid approach (Gemini search + Cerebras LLM)
- **Production-ready** with error handling and logging

**Next Steps:**
1. Test Gemini mode with sample PDFs
2. Compare answer quality
3. Monitor costs for 1 week
4. Decide which mode to use long-term
5. Optionally shut down Railway backend if Gemini works well

---

**Questions?** Check the logs for `[GEMINI]` or `[SELF-HOSTED]` messages to see which mode is active!
